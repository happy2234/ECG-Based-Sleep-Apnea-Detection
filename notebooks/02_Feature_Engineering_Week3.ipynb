{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe_intro",
   "metadata": {},
   "source": [
    "# Week 3: Feature Engineering\n",
    "## Extracting Features from ECG (RR Intervals) and SpO2 Signals\n",
    "\n",
    "**Objective**: Calculate Time-Domain, Frequency-Domain, Non-Linear, and SpO2 features for Sleep Apnea Detection.\n",
    "\n",
    "### Feature Sets:\n",
    "1. **Time-Domain**: Mean RR, SDNN, RMSSD, pNN50\n",
    "2. **Frequency-Domain**: Avg Power (LF, HF), LF/HF Ratio\n",
    "3. **Non-Linear**: SD1, SD2 (Poincare Plot)\n",
    "4. **SpO2 Features**: Mean Saturation, ODI (Dips > 3%)\n",
    "\n",
    "### Pipeline:\n",
    "1. Load Data (from .mat files)\n",
    "2. Preprocess (Filter Artifacts)\n",
    "3. Extract Features per Segment\n",
    "4. Aggregate into Feature Matrix (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "imports",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:56.194845Z",
     "iopub.status.busy": "2026-02-08T16:09:56.194696Z",
     "iopub.status.idle": "2026-02-08T16:09:57.100343Z",
     "shell.execute_reply": "2026-02-08T16:09:57.099974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "import scipy.signal\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(\"Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "config",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.101841Z",
     "iopub.status.busy": "2026-02-08T16:09:57.101671Z",
     "iopub.status.idle": "2026-02-08T16:09:57.104969Z",
     "shell.execute_reply": "2026-02-08T16:09:57.104543Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configuration\n",
    "DATA_PATH = '../APNEA HRV+SPO2 DATASET/HuGCDN2014-OXI'\n",
    "FOLDERS = {'C': 'C', 'D': 'D', 'ND': 'ND'}\n",
    "FS_RR = 1  # RR intervals are essentially discrete events, but derived from freq\n",
    "       # Actually, for spectral analysis of RR series, we usually resample to e.g. 4Hz\n",
    "\n",
    "def load_mat_data(filename, folder, key_hint):\n",
    "    # Handle potential subfolders 'RR' and 'SAT' which seem to separate data types\n",
    "    # Inspecting file structure showed folders C, D, ND directly under data path\n",
    "    # But script showed sample files in subdirs. Let's try flexible loading.\n",
    "    \n",
    "    # Actually list_dir output showed:\n",
    "    # DATA_PATH/RR/C1.mat etc\n",
    "    # DATA_PATH/SAT/C1.mat etc\n",
    "    # So structure is likely: TYPE/Filename\n",
    "    \n",
    "    # Adjust path logic based on inspection\n",
    "    # We need to construct path: DATA_PATH / TYPE / FILENAME\n",
    "    # filename e.g. 'C1.mat'\n",
    "    # folder (label) is inferred from filename prefix\n",
    "    \n",
    "    if 'RR' in key_hint:\n",
    "        sub = 'RR'\n",
    "    else:\n",
    "        sub = 'SAT'\n",
    "        \n",
    "    path = os.path.join(DATA_PATH, sub, filename)\n",
    "    \n",
    "    if not os.path.exists(path):\n",
    "        # Fallback to direct folder if flattened\n",
    "        path = os.path.join(DATA_PATH, folder, filename)\n",
    "\n",
    "    try:\n",
    "        mat = scipy.io.loadmat(path)\n",
    "        keys = [k for k in mat.keys() if not k.startswith('__')]\n",
    "        for k in keys:\n",
    "            if key_hint in k:\n",
    "                return mat[k]\n",
    "        # Fallback: return first key if specific hint not found\n",
    "        return mat[keys[0]] if keys else None\n",
    "    except Exception as e:\n",
    "        # print(f\"Error loading {path}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "time_domain_md",
   "metadata": {},
   "source": [
    "## 1. Time-Domain Features\n",
    "- **Mean RR**: Average time between beats.\n",
    "- **SDNN**: Standard deviation of NN (RR) intervals.\n",
    "- **RMSSD**: Root mean square of successive differences.\n",
    "- **pNN50**: Percentage of successive RR intervals differing by > 50ms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "time_domain_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.106074Z",
     "iopub.status.busy": "2026-02-08T16:09:57.105972Z",
     "iopub.status.idle": "2026-02-08T16:09:57.108385Z",
     "shell.execute_reply": "2026-02-08T16:09:57.107882Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_time_domain_features(rr_intervals):\n",
    "    if len(rr_intervals) < 2:\n",
    "        return [np.nan] * 4\n",
    "    \n",
    "    diff_rr = np.diff(rr_intervals)\n",
    "    \n",
    "    mean_rr = np.mean(rr_intervals)\n",
    "    sdnn = np.std(rr_intervals, ddof=1)\n",
    "    rmssd = np.sqrt(np.mean(diff_rr ** 2))\n",
    "    pnn50 = np.sum(np.abs(diff_rr) > 50) / len(diff_rr) * 100\n",
    "    \n",
    "    return [mean_rr, sdnn, rmssd, pnn50]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "freq_domain_md",
   "metadata": {},
   "source": [
    "## 2. Frequency-Domain Features\n",
    "Using Welch's method to estimate Power Spectral Density (PSD).\n",
    "- **VLF**: Very Low Frequency (0.0033 - 0.04 Hz)\n",
    "- **LF**: Low Frequency (0.04 - 0.15 Hz)\n",
    "- **HF**: High Frequency (0.15 - 0.4 Hz)\n",
    "- **LF/HF Ratio**: Sympathovagal balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "freq_domain_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.109373Z",
     "iopub.status.busy": "2026-02-08T16:09:57.109278Z",
     "iopub.status.idle": "2026-02-08T16:09:57.112461Z",
     "shell.execute_reply": "2026-02-08T16:09:57.112015Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def get_freq_domain_features(rr_intervals):\n",
    "    if len(rr_intervals) < 2:\n",
    "        return [np.nan] * 4\n",
    "        \n",
    "    # Resample RR intervals to 4Hz for uniform sampling (required for FFT/Welch)\n",
    "    # Create time axis\n",
    "    time_cumsum = np.cumsum(rr_intervals) / 1000.0\n",
    "    time_cumsum = time_cumsum - time_cumsum[0]\n",
    "    \n",
    "    # Interpolation function\n",
    "    f_interp = interp1d(time_cumsum, rr_intervals, kind='cubic', fill_value=\"extrapolate\")\n",
    "    \n",
    "    # New time axis (4Hz)\n",
    "    fs = 4.0\n",
    "    steps = 1 / fs\n",
    "    new_time = np.arange(0, time_cumsum[-1], steps)\n",
    "    rr_interpolated = f_interp(new_time)\n",
    "    \n",
    "    # Detrend\n",
    "    rr_detrended = scipy.signal.detrend(rr_interpolated)\n",
    "    \n",
    "    # Welch's Periodogram\n",
    "    f, Pxx = scipy.signal.welch(rr_detrended, fs=fs, nperseg=256)\n",
    "    \n",
    "    # Band Power\n",
    "    # VLF: 0.0033 - 0.04 Hz\n",
    "    # LF: 0.04 - 0.15 Hz\n",
    "    # HF: 0.15 - 0.4 Hz\n",
    "    \n",
    "    vlf_mask = (f >= 0.0033) & (f < 0.04)\n",
    "    lf_mask = (f >= 0.04) & (f < 0.15)\n",
    "    hf_mask = (f >= 0.15) & (f < 0.4)\n",
    "    \n",
    "    vlf_power = np.trapz(Pxx[vlf_mask], f[vlf_mask])\n",
    "    lf_power = np.trapz(Pxx[lf_mask], f[lf_mask])\n",
    "    hf_power = np.trapz(Pxx[hf_mask], f[hf_mask])\n",
    "    \n",
    "    lf_hf_ratio = lf_power / hf_power if hf_power > 0 else 0\n",
    "    \n",
    "    return [vlf_power, lf_power, hf_power, lf_hf_ratio]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nonlinear_md",
   "metadata": {},
   "source": [
    "## 3. Non-Linear Features\n",
    "Poincare Plot Geometry (SD1, SD2).\n",
    "- **SD1**: Short-term variability (width of ellipse).\n",
    "- **SD2**: Long-term variability (length of ellipse)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "nonlinear_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.113588Z",
     "iopub.status.busy": "2026-02-08T16:09:57.113488Z",
     "iopub.status.idle": "2026-02-08T16:09:57.115793Z",
     "shell.execute_reply": "2026-02-08T16:09:57.115423Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_nonlinear_features(rr_intervals):\n",
    "    if len(rr_intervals) < 2:\n",
    "        return [np.nan] * 2\n",
    "        \n",
    "    # RR(n) vs RR(n+1)\n",
    "    x = rr_intervals[:-1]\n",
    "    y = rr_intervals[1:]\n",
    "    \n",
    "    # SD1, SD2 calculation\n",
    "    sd1 = np.std(np.subtract(x, y) / np.sqrt(2))\n",
    "    sd2 = np.std(np.add(x, y) / np.sqrt(2))\n",
    "    \n",
    "    return [sd1, sd2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "spo2_feat_md",
   "metadata": {},
   "source": [
    "## 4. SpO2 Features\n",
    "- **Mean SpO2**: Average oxygen saturation.\n",
    "- **Min SpO2**: Minimum value.\n",
    "- **ODI (Oxygen Desaturation Index)**: Number of times SpO2 drops by > 3% from baseline (approx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "spo2_feat_code",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.116974Z",
     "iopub.status.busy": "2026-02-08T16:09:57.116870Z",
     "iopub.status.idle": "2026-02-08T16:09:57.119397Z",
     "shell.execute_reply": "2026-02-08T16:09:57.119024Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_spo2_features(spo2_signal):\n",
    "    if len(spo2_signal) == 0:\n",
    "        return [np.nan] * 3\n",
    "        \n",
    "    mean_sat = np.mean(spo2_signal)\n",
    "    min_sat = np.min(spo2_signal)\n",
    "    \n",
    "    # Simple ODI calculation: Count drops > 3%\n",
    "    # 1. Start from baseline (e.g., median)\n",
    "    # 2. Find local dips\n",
    "    # This is a simplified version. \n",
    "    \n",
    "    # Calculate difference from baseline\n",
    "    baseline = np.median(spo2_signal)\n",
    "    \n",
    "    # Count desaturation events (simplified)\n",
    "    desats = 0\n",
    "    in_event = False\n",
    "    for val in spo2_signal:\n",
    "        if val < (baseline - 3):\n",
    "            if not in_event:\n",
    "                desats += 1\n",
    "                in_event = True\n",
    "        else:\n",
    "            in_event = False\n",
    "            \n",
    "    # ODI is events per hour. \n",
    "    # Assuming signal duration is known or calculated from length / sampling_rate\n",
    "    # Here we just return raw count for the segment, normalization happens later if segment time is known\n",
    "    \n",
    "    return [mean_sat, min_sat, desats]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pipeline_md",
   "metadata": {},
   "source": [
    "## 5. Main Processing Loop\n",
    "Iterate through all files, clean segments, extract features, and build the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "main_loop",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:09:57.120377Z",
     "iopub.status.busy": "2026-02-08T16:09:57.120271Z",
     "iopub.status.idle": "2026-02-08T16:10:53.416386Z",
     "shell.execute_reply": "2026-02-08T16:10:53.415703Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Extraction Complete\n",
      "label\n",
      "C     38\n",
      "D     34\n",
      "ND    11\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>label</th>\n",
       "      <th>mean_rr</th>\n",
       "      <th>sdnn</th>\n",
       "      <th>rmssd</th>\n",
       "      <th>pnn50</th>\n",
       "      <th>vlf_power</th>\n",
       "      <th>lf_power</th>\n",
       "      <th>hf_power</th>\n",
       "      <th>lf_hf_ratio</th>\n",
       "      <th>sd1</th>\n",
       "      <th>sd2</th>\n",
       "      <th>mean_spo2</th>\n",
       "      <th>min_spo2</th>\n",
       "      <th>odi_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C1.mat</td>\n",
       "      <td>C</td>\n",
       "      <td>913.388545</td>\n",
       "      <td>94.160944</td>\n",
       "      <td>14.975915</td>\n",
       "      <td>0.559917</td>\n",
       "      <td>327.971893</td>\n",
       "      <td>323.908679</td>\n",
       "      <td>55.926886</td>\n",
       "      <td>5.791645</td>\n",
       "      <td>10.589571</td>\n",
       "      <td>132.741503</td>\n",
       "      <td>96.025473</td>\n",
       "      <td>91.979858</td>\n",
       "      <td>1076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C10.mat</td>\n",
       "      <td>C</td>\n",
       "      <td>979.519626</td>\n",
       "      <td>118.289132</td>\n",
       "      <td>29.716227</td>\n",
       "      <td>7.568275</td>\n",
       "      <td>510.068515</td>\n",
       "      <td>820.147754</td>\n",
       "      <td>245.433851</td>\n",
       "      <td>3.341624</td>\n",
       "      <td>21.012545</td>\n",
       "      <td>165.960066</td>\n",
       "      <td>96.480269</td>\n",
       "      <td>90.989548</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C11.mat</td>\n",
       "      <td>C</td>\n",
       "      <td>704.911414</td>\n",
       "      <td>52.355440</td>\n",
       "      <td>13.405367</td>\n",
       "      <td>0.545485</td>\n",
       "      <td>188.951448</td>\n",
       "      <td>151.283596</td>\n",
       "      <td>60.708957</td>\n",
       "      <td>2.491949</td>\n",
       "      <td>9.479026</td>\n",
       "      <td>73.432123</td>\n",
       "      <td>96.980014</td>\n",
       "      <td>80.549325</td>\n",
       "      <td>4389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C12.mat</td>\n",
       "      <td>C</td>\n",
       "      <td>856.033064</td>\n",
       "      <td>72.529749</td>\n",
       "      <td>16.815397</td>\n",
       "      <td>1.196960</td>\n",
       "      <td>248.683406</td>\n",
       "      <td>305.093759</td>\n",
       "      <td>82.317545</td>\n",
       "      <td>3.706303</td>\n",
       "      <td>11.890281</td>\n",
       "      <td>101.880023</td>\n",
       "      <td>95.653068</td>\n",
       "      <td>74.338903</td>\n",
       "      <td>2110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C13.mat</td>\n",
       "      <td>C</td>\n",
       "      <td>989.164798</td>\n",
       "      <td>109.755166</td>\n",
       "      <td>44.184377</td>\n",
       "      <td>20.621179</td>\n",
       "      <td>823.901691</td>\n",
       "      <td>843.240759</td>\n",
       "      <td>575.640730</td>\n",
       "      <td>1.464873</td>\n",
       "      <td>31.243072</td>\n",
       "      <td>152.040033</td>\n",
       "      <td>97.470270</td>\n",
       "      <td>61.039139</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  filename label     mean_rr        sdnn      rmssd      pnn50   vlf_power  \\\n",
       "0   C1.mat     C  913.388545   94.160944  14.975915   0.559917  327.971893   \n",
       "1  C10.mat     C  979.519626  118.289132  29.716227   7.568275  510.068515   \n",
       "2  C11.mat     C  704.911414   52.355440  13.405367   0.545485  188.951448   \n",
       "3  C12.mat     C  856.033064   72.529749  16.815397   1.196960  248.683406   \n",
       "4  C13.mat     C  989.164798  109.755166  44.184377  20.621179  823.901691   \n",
       "\n",
       "     lf_power    hf_power  lf_hf_ratio        sd1         sd2  mean_spo2  \\\n",
       "0  323.908679   55.926886     5.791645  10.589571  132.741503  96.025473   \n",
       "1  820.147754  245.433851     3.341624  21.012545  165.960066  96.480269   \n",
       "2  151.283596   60.708957     2.491949   9.479026   73.432123  96.980014   \n",
       "3  305.093759   82.317545     3.706303  11.890281  101.880023  95.653068   \n",
       "4  843.240759  575.640730     1.464873  31.243072  152.040033  97.470270   \n",
       "\n",
       "    min_spo2  odi_count  \n",
       "0  91.979858       1076  \n",
       "1  90.989548        646  \n",
       "2  80.549325       4389  \n",
       "3  74.338903       2110  \n",
       "4  61.039139        144  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This cell will take time to run\n",
    "features_list = []\n",
    "\n",
    "# Iterate over 'RR' folder since paired files exist in 'SAT'\n",
    "rr_base_path = os.path.join(DATA_PATH, 'RR')\n",
    "\n",
    "if os.path.exists(rr_base_path):\n",
    "    files = [f for f in os.listdir(rr_base_path) if f.endswith('.mat')]\n",
    "    \n",
    "    for i, filename in enumerate(files):\n",
    "        # Infer label from filename\n",
    "        label = 'ND' if filename.startswith('ND') else ('D' if filename.startswith('D') else 'C')\n",
    "        \n",
    "        # Load data\n",
    "        rr_data = load_mat_data(filename, label, 'RR')\n",
    "        spo2_data = load_mat_data(filename, label, 'SAT')\n",
    "        \n",
    "        # Handle segmentation (assuming cleaned)\n",
    "        # For this dataset, data is often split into segments within the file or just one long recording\n",
    "        # We will treat the whole file as one recording for simplicity or iterate if cells\n",
    "        \n",
    "        # Flatten RR\n",
    "        full_rr = np.array([])\n",
    "        if rr_data is not None:\n",
    "            if rr_data.dtype == 'O':\n",
    "                valid = [c.flatten() for c in rr_data.flatten() if c.size > 0]\n",
    "                if valid: full_rr = np.concatenate(valid)\n",
    "            else:\n",
    "                full_rr = rr_data.flatten()\n",
    "        \n",
    "        # Flatten SpO2\n",
    "        full_spo2 = np.array([])\n",
    "        if spo2_data is not None:\n",
    "             if spo2_data.dtype == 'O':\n",
    "                valid = [c.flatten() for c in spo2_data.flatten() if c.size > 0]\n",
    "                if valid: full_spo2 = np.concatenate(valid)\n",
    "             else:\n",
    "                full_spo2 = spo2_data.flatten()\n",
    "                \n",
    "        # Skip empty\n",
    "        if full_rr.size < 100 or full_spo2.size < 100:\n",
    "            continue\n",
    "            \n",
    "        # --- Cleaning ---\n",
    "        # RR: 300 - 2000 ms\n",
    "        mask_rr = (full_rr >= 300) & (full_rr <= 2000)\n",
    "        clean_rr = full_rr[mask_rr]\n",
    "        \n",
    "        # SpO2: 50 - 100 %\n",
    "        mask_spo2 = (full_spo2 >= 50) & (full_spo2 <= 100)\n",
    "        clean_spo2 = full_spo2[mask_spo2]\n",
    "        \n",
    "        if clean_rr.size < 100:\n",
    "             continue\n",
    "\n",
    "        # --- Feature Extraction ---\n",
    "        # Time-Domain\n",
    "        td = get_time_domain_features(clean_rr)\n",
    "        \n",
    "        # Frequency-Domain\n",
    "        fd = get_freq_domain_features(clean_rr)\n",
    "        \n",
    "        # Non-Linear\n",
    "        nl = get_nonlinear_features(clean_rr)\n",
    "        \n",
    "        # SpO2\n",
    "        sp = get_spo2_features(clean_spo2)\n",
    "        \n",
    "        # Compile\n",
    "        feat_row = {\n",
    "            'filename': filename,\n",
    "            'label': label,\n",
    "            'mean_rr': td[0], 'sdnn': td[1], 'rmssd': td[2], 'pnn50': td[3],\n",
    "            'vlf_power': fd[0], 'lf_power': fd[1], 'hf_power': fd[2], 'lf_hf_ratio': fd[3],\n",
    "            'sd1': nl[0], 'sd2': nl[1],\n",
    "            'mean_spo2': sp[0], 'min_spo2': sp[1], 'odi_count': sp[2]\n",
    "        }\n",
    "        \n",
    "        features_list.append(feat_row)\n",
    "\n",
    "# Create DataFrame\n",
    "if not features_list:\n",
    "    print(\"No features extracted. Check data path or loading logic.\")\n",
    "    df_features = pd.DataFrame(columns=['filename', 'label', 'mean_rr', 'sdnn', 'rmssd', 'pnn50', 'vlf_power', 'lf_power', 'hf_power', 'lf_hf_ratio', 'sd1', 'sd2', 'mean_spo2', 'min_spo2', 'odi_count'])\n",
    "else:\n",
    "    df_features = pd.DataFrame(features_list)\n",
    "    print(\"Feature Extraction Complete\")\n",
    "    if 'label' in df_features.columns:\n",
    "        print(df_features.groupby('label').size())\n",
    "    else:\n",
    "        print(\"Label column missing from DataFrame\")\n",
    "df_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "save",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-02-08T16:10:53.417839Z",
     "iopub.status.busy": "2026-02-08T16:10:53.417729Z",
     "iopub.status.idle": "2026-02-08T16:10:53.421965Z",
     "shell.execute_reply": "2026-02-08T16:10:53.421532Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features saved to ../processed_data/extracted_features.csv\n"
     ]
    }
   ],
   "source": [
    "# Save to CSV\n",
    "output_dir = '../processed_data'\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "output_path = os.path.join(output_dir, 'extracted_features.csv')\n",
    "df_features.to_csv(output_path, index=False)\n",
    "print(f\"Features saved to {output_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
